Yelp Big Data Sentiment Analysis Project

This project was developed as part of a university assignment focused on large-scale data processing and sentiment classification using the Yelp Open Dataset. It demonstrates how distributed systems and machine learning can be integrated to analyze millions of customer reviews.
---

ğŸ”§ Technologies & Tools

- Apache Spark 3.5.3 (via PySpark)
- Apache Hive 3.1.3
- Google Cloud Dataproc
- Google Cloud Storage (GCS)
- Python 3.x
- Libraries: Pandas, Scikit-learn, Matplotlib, Seaborn

--
ğŸ“ Project Structure

	â€¢	yelp_sentiment_pipline.ipynb: Complete and reproducible code in Google Colab (Spark + Python)
	â€¢	yelp_analysis_hive.sql: Hive queries used for analytical tasks
	â€¢	screenshots/: Selected output screenshots and visualizations
---

ğŸ“Œ Key Tasks Performed

ğŸ§¹ 1. Data Ingestion & Cleaning
	â€¢	Loaded business.json and review.json from GCS using PySpark
	â€¢	Filtered for restaurant-related data and joined on business IDs
	â€¢	Cleaned and saved the final dataset in Parquet format (42 files, ~5M reviews)

ğŸ“Š 2. Data Analysis with Spark & Hive
	â€¢	Performed three analytical queries using both SparkSQL and Hive:
	â€¢	Sentiment distribution based on labeled reviews
	â€¢	Average review stars by city
	â€¢	Distribution of businesses by review count
	â€¢	Compared execution time and output consistency between Spark and Hive

ğŸ¤– 3. Sentiment Classification (Machine Learning)
	â€¢	Labeled sentiments based on star ratings:
	â€¢	â‰¥ 4 stars â†’ Positive
	â€¢	= 3 stars â†’ Neutral
	â€¢	â‰¤ 2 stars â†’ Negative
	â€¢	Used TF-IDF to vectorize review texts
	â€¢	Trained a Random Forest Classifier using Spark MLlib
	â€¢	Evaluated model performance with F1, accuracy, precision, and recall
	â€¢	Visualized results using a confusion matrix

---

ğŸ“‚ Screenshots

A collection of output screenshots is included in the screenshots/ folder for reference.

---

ğŸ“Š Dataset

- Source: [Yelp Open Dataset](https://www.yelp.com/dataset)
- Files used: `business.json`, `review.json`
- Data Size: ~5M reviews; cleaned subset stored as 42 Parquet files on GCS

---

ğŸ“Œ Notes

	â€¢	The project was implemented entirely in Google Colab, using Apache Spark and Hive deployed on Google Cloud Dataproc
	â€¢	All processing, analysis, and model training were performed in the cloud
	â€¢	Outputs were exported to GCS for visualization and reporting
